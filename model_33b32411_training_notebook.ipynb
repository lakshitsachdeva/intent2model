{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Model Training: Predicting sepal.length\n",
    "\n",
    "This notebook was auto-generated by Intent2Model.\n",
    "\n",
    "**Task:** regression\n",
    "**Target Column:** sepal.length\n",
    "**Model:** ridge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLANNING SOURCE\n\n**Planning Method:** FALLBACK\n**Error:** Gemini API error: All Gemini models hit rate limits. Tried: gemini-2.5-flash, gemini-2.5-flash-lite, gemini-flash-latest, gemini-2.5-pro. Please wait or provide a different API key. Last error: Model gemini-1.5-pro not found\n\n**Target Confidence:** 0.95\n**Task Confidence:** 0.90\n**Plan Quality:** High Confidence\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 0 \u2014 TASK INFERENCE\n\n\u26a0\ufe0f Rule-based fallback task inference (LLM unavailable). Low confidence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1 \u2014 DATASET INTELLIGENCE\n\n\u26a0\ufe0f Rule-based fallback dataset intelligence (LLM unavailable). Limited analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2 \u2014 TRANSFORMATION STRATEGY\n\n\u26a0\ufe0f Rule-based fallback transformation strategy (LLM unavailable). Conservative defaults.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3 \u2014 MODEL CANDIDATE SELECTION\n\n\u26a0\ufe0f Rule-based fallback model selection (LLM unavailable). Baseline models only.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4 \u2014 TRAINING & VALIDATION\n\nUse cross-validation by default with task-appropriate metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5 \u2014 ERROR & BEHAVIOR ANALYSIS\n\nAnalyze residuals/confusion matrix and error slices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 6 \u2014 EXPLAINABILITY\n\nUse feature_importances_ when available and align post-encoding names.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load your dataset\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# For this example, we'll use the uploaded data\n",
    "print(f'Dataset shape: {df.shape}')\n",
    "print(f'Columns: {list(df.columns)}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Separate features and target\n",
    "X = df.drop(columns=['sepal.length'])\n",
    "y = df['sepal.length']\n",
    "\n",
    "# Handle categorical target if needed\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'Training set: {X_train.shape}')\n",
    "print(f'Test set: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build Preprocessing Pipeline (from AutoMLPlan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Preprocessing compiled from AutoMLPlan\n# Each feature transform is based on plan.feature_transforms\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\nfrom sklearn.impute import SimpleImputer\n\ntransformers = []\n\n# Numeric features without scaling (from plan): ['sepal.width', 'petal.length', 'petal.width']\nnum_plain_cols = ['sepal.width', 'petal.length', 'petal.width']\nif num_plain_cols:\n    transformers.append((\n        'num_plain',\n        'passthrough',\n        num_plain_cols\n    ))\n\n# Categorical features: one-hot encoding (from plan): ['variety']\ncat_onehot_cols = ['variety']\nif cat_onehot_cols:\n    steps = []\n    try:\n        ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False, min_frequency=5)\n    except TypeError:\n        ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n    steps.append(('onehot', ohe))\n    transformers.append(('cat_onehot', Pipeline(steps), cat_onehot_cols))\n\n# Create preprocessor from plan-driven transformers\n\nif len(transformers) == 0:\n    # \u26a0\ufe0f WARNING: No transformers generated from plan.feature_transforms! Using runtime fallback.\n    numeric_cols = ['sepal.width', 'petal.length', 'petal.width']\n    transformers.append(('num_scaled', Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]), numeric_cols))\n    categorical_cols = ['variety']\n    try:\n        ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False, min_frequency=5)\n    except TypeError:\n        ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n    transformers.append(('cat_onehot', Pipeline([('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', ohe)]), categorical_cols))\npreprocessor = ColumnTransformer(transformers, remainder='drop')\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build Model (from AutoMLPlan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Model compiled from AutoMLPlan.model_candidates\n\n# Selected model: linear_regression (from plan.model_candidates)\n# Reason: Baseline linear model for calibration.\n\nfrom sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Assemble Pipeline (from AutoMLPlan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Assemble pipeline from plan-driven components\npipeline = Pipeline([\n    ('preprocessor', preprocessor),\n    ('model', model)\n])\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate using metrics from AutoMLPlan\n",
    "# Metrics compiled from AutoMLPlan\n# Primary metric: rmse\n# Additional metrics: ['mae', 'r2']\n\nfrom sklearn.metrics import (\n    mean_squared_error,\n    mean_absolute_error,\n    r2_score\n)\n\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "primary_score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f'Primary Metric (RMSE): {primary_score:.4f}')\n",
    "\n# Additional metrics from plan:\n",
    "print(f'MAE: {mean_absolute_error(y_test, y_pred):.4f}')\n",
    "print(f'R\u00b2: {r2_score(y_test, y_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance (from plan.explainability_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get feature importance (aligned with plan)\n",
    "if hasattr(pipeline.named_steps['model'], 'feature_importances_'):\n",
    "    importances = pipeline.named_steps['model'].feature_importances_\n",
    "    \n",
    "    # Get feature names after preprocessing (aligned with plan, not dtype-based)\n",
    "    # NOTE: Do NOT use numeric_cols or categorical_cols - they may not be defined\n",
    "    try:\n",
    "        preprocessor = pipeline.named_steps['preprocessor']\n",
    "        feature_names = []\n",
    "        # Get feature names from preprocessor transformers\n",
    "        if hasattr(preprocessor, 'transformers_'):\n",
    "            for name, transformer, cols in preprocessor.transformers_:\n",
    "                if hasattr(transformer, 'get_feature_names_out'):\n",
    "                    feature_names.extend(transformer.get_feature_names_out(cols))\n",
    "                elif hasattr(transformer, 'named_steps'):\n",
    "                    # Pipeline transformer\n",
    "                    for step_name, step_transformer in transformer.named_steps.items():\n",
    "                        if hasattr(step_transformer, 'get_feature_names_out'):\n",
    "                            feature_names.extend(step_transformer.get_feature_names_out(cols))\n",
    "                            break\n",
    "                else:\n",
    "                    # Fallback: use column names\n",
    "                    feature_names.extend([f'{name}_{col}' for col in cols])\n",
    "        else:\n",
    "            # Preprocessor not fitted yet - use generic names\n",
    "            feature_names = [f'feature_{i}' for i in range(len(importances))]\n",
    "    except Exception as e:\n",
    "        # Fallback: use generic feature names\n",
    "        feature_names = [f'feature_{i}' for i in range(len(importances))]\n",
    "    \n",
    "    # Create importance DataFrame\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names[:len(importances)],\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=importance_df.head(10), x='importance', y='feature')\n",
    "    plt.title('Top 10 Feature Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(importance_df)\n",
    "else:\n",
    "    print('Feature importance not available for this model type.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save the trained model\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(pipeline, f)\n",
    "\n",
    "print('Model saved successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load model for predictions\n",
    "# with open('model.pkl', 'rb') as f:\n",
    "#     loaded_model = pickle.load(f)\n",
    "\n",
    "# Example prediction\n",
    "# new_data = pd.DataFrame({...})\n",
    "# prediction = loaded_model.predict(new_data)\n",
    "# print(f'Prediction: {prediction}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}