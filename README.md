# Intent2Model ğŸš€

LLM-Guided AutoML Agent - Upload a CSV, chat with the AI, get a trained model.

## âš¡ Quick Start (Easiest Way)

```bash
# Make scripts executable (first time only)
chmod +x start.sh stop.sh

# Start everything
./start.sh
```

Then open **http://localhost:3000** in your browser!

To stop: Press `Ctrl+C` or run `./stop.sh`

---

## ğŸ“– How to Use

### 1. Upload CSV
- Drag & drop your CSV file or click "choose file"
- System analyzes it automatically

### 2. Train Model
Just type a column name in the chat:
- **"variety"** â†’ trains model to predict "variety"
- **"price"** â†’ trains model to predict "price"
- Or any column name from your dataset

### 3. View Results
- **"report"** â†’ shows beautiful charts and metrics
- **"show me results"** â†’ displays model performance

### 4. Make Predictions
- **"predict"** or **"can you predict for me?"** â†’ starts prediction flow
- Provide feature values: **"sepal.length: 5.1, sepal.width: 3.5"**

---

## ğŸ’¬ Example Conversation

```
You: [uploads iris.csv]
AI: âœ“ analyzed your dataset â€¢ 150 rows â€¢ 5 columns
AI: suggested targets: variety, sepal.length, sepal.width

You: variety
AI: ğŸš€ training model to predict "variety"...
AI: âœ… model trained successfully!
AI: accuracy: 1.000 â€¢ best model: RandomForest
AI: [shows charts]

You: report
AI: [shows detailed charts: metrics, feature importance, CV scores]

You: predict
AI: sure! i need: sepal.length, sepal.width, petal.length, petal.width

You: sepal.length: 5.1, sepal.width: 3.5, petal.length: 1.4, petal.width: 0.2
AI: ğŸ¯ prediction: Setosa
AI: probabilities: Setosa 99.8%, Versicolor 0.2%, Virginica 0.0%
```

---

## ğŸ› ï¸ Manual Setup (Alternative)

### Backend
**Important:** Always run uvicorn from inside the `backend/` folder. Running from project root will fail with "Could not import module main".

```bash
cd backend
pip install -r ../requirements.txt
# Optional: set API key in .env or export GEMINI_API_KEY=your_key
python3 -m uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

Or use the helper script (from project root):
```bash
chmod +x backend/run.sh
./backend/run.sh
```

**Backend nahi chal raha?**
- **"Could not import module main"** â†’ You're in the wrong folder. Run `cd backend` first, then `python3 -m uvicorn main:app --host 0.0.0.0 --port 8000`.
- **"Address already in use" / port 8000** â†’ Free the port: `lsof -ti:8000 | xargs kill -9`, then start again.
- **Dependencies missing** â†’ From project root: `pip install -r requirements.txt` (or use `./start.sh` â€” it creates a venv and installs deps).

### Frontend (New Terminal)
```bash
cd frontend
npm install
npm run dev
```

Visit **http://localhost:3000**

---

## ğŸ¨ Features

- ğŸ“Š **Beautiful Charts**: Metrics, feature importance, CV scores
- ğŸ¨ **Extravagant UI**: Gradient colors, smooth animations
- ğŸ¤– **LLM-Powered**: Gemini AI generates optimal pipelines
- ğŸ”® **Smart Predictions**: Chat-based prediction interface
- ğŸ“ˆ **Model Comparison**: Tries multiple models, picks best
- âš¡ **Auto-Detection**: Automatically detects task type and metrics

---

## ğŸ“ Requirements

- Python 3.10+
- Node.js 18+
- npm/yarn

Install dependencies:
```bash
# Backend
pip install -r requirements.txt

# Frontend
cd frontend
npm install
```

---

## ğŸ› Troubleshooting

**Services not starting?**
- Check ports: `lsof -i :8000` and `lsof -i :3000`
- Check logs: `tail -f backend.log` or `tail -f frontend.log`

**Training errors?**
- Make sure CSV has valid data
- Check that target column exists
- Try a different column name

---

## drift â€” Terminal-first CLI

**drift** by Lakshit Sachdeva. Terminal-first, chat-based AutoML â€” same engine as the web UI. No commands to memorize.

### Exactly what to do (any computer)

1. **Install drift** (pick one):
   ```bash
   npm install -g drift-ml
   ```
   or:
   ```bash
   pipx install drift
   ```

2. **Run drift:**
   ```bash
   drift
   ```
   Youâ€™ll see the welcome and step-by-step instructions in the terminal.

3. **Engine** â€” On first run the CLI downloads and starts the drift engine locally (or set `DRIFT_BACKEND_URL` to a running engine). You need an LLM: Gemini CLI, Ollama, or another local LLM.

4. **In drift:** type `load path/to/your.csv`, then chat (e.g. `predict price`, `try something stronger`). Type `quit` to exit.

drift shows you the rest when you run it.

### Install (details)

- **Local-first** â€” Same engine as the web app; planning and training run on your machine.
- **Chat-based**: e.g. `load iris.csv`, `predict price`, `try something stronger`, `why is accuracy capped`.
- **Engine** runs locally (CLI auto-starts it or use `DRIFT_BACKEND_URL`). Web UI can be hosted on Vercel.

---

## ğŸ“š More Info

See `HOW_TO_USE.md` for detailed instructions and examples.

---

**That's it! Just run `./start.sh` and start chatting! ğŸ‰**
